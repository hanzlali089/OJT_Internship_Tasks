{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277c953b",
   "metadata": {},
   "source": [
    "# Image classification through facial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d5da5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5422fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []  # List to store image and label pairs\n",
    "\n",
    "# List of folder paths\n",
    "folder_paths = [\n",
    "    r\"C:\\Users\\user\\Desktop\\gender\\test\\female\",\n",
    "    r\"C:\\Users\\user\\Desktop\\gender\\test\\male\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1488fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the folder paths\n",
    "for i in folder_paths:\n",
    "    folder_name = os.path.basename(i)\n",
    "    \n",
    "    # Iterate over the images in the subdirectory\n",
    "    for file_name in os.listdir(i):\n",
    "        image_path = os.path.join(i, file_name)\n",
    "        \n",
    "        if os.path.isfile(image_path):  # Only consider files\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # If the image was successfully loaded\n",
    "            if image is not None:\n",
    "                # Resize the grayscale image to 250X250 pixels\n",
    "                resized_image = cv2.resize(image, (250, 250))\n",
    "                \n",
    "                # Flatten the image and append each pixel as a separate feature along with the label to the dataset\n",
    "                flattened_image = resized_image.flatten().tolist()\n",
    "                dataset.append(flattened_image + [folder_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a3ff5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>pixel_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_62492</th>\n",
       "      <th>pixel_62493</th>\n",
       "      <th>pixel_62494</th>\n",
       "      <th>pixel_62495</th>\n",
       "      <th>pixel_62496</th>\n",
       "      <th>pixel_62497</th>\n",
       "      <th>pixel_62498</th>\n",
       "      <th>pixel_62499</th>\n",
       "      <th>pixel_62500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>139</td>\n",
       "      <td>135</td>\n",
       "      <td>132</td>\n",
       "      <td>130</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>168</td>\n",
       "      <td>166</td>\n",
       "      <td>164</td>\n",
       "      <td>163</td>\n",
       "      <td>162</td>\n",
       "      <td>161</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>246</td>\n",
       "      <td>245</td>\n",
       "      <td>244</td>\n",
       "      <td>242</td>\n",
       "      <td>244</td>\n",
       "      <td>246</td>\n",
       "      <td>249</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>91</td>\n",
       "      <td>104</td>\n",
       "      <td>135</td>\n",
       "      <td>166</td>\n",
       "      <td>171</td>\n",
       "      <td>169</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>133</td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>102</td>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 62501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  pixel_8  \\\n",
       "0         57       58       69       81       90       90       90       91   \n",
       "1        143      142      139      135      132      130      128      128   \n",
       "2         10       10       10       11       11       10       10        9   \n",
       "3         50       50       49       48       47       46       45       44   \n",
       "4         20       20       18       17       16       15       14       14   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "195       20       20       19       19       19       22       26       30   \n",
       "196       22       22       21       20       19       17       15       13   \n",
       "197       51       51       53       56       58       58       55       54   \n",
       "198       64       63       57       51       47       54       60       61   \n",
       "199      128      128      133      138      143      146      150      152   \n",
       "\n",
       "     pixel_9  pixel_10  ...  pixel_62492  pixel_62493  pixel_62494  \\\n",
       "0         92        93  ...           30           27           27   \n",
       "1        127       126  ...           35           35           35   \n",
       "2         10        10  ...          169          168          166   \n",
       "3         44        43  ...          246          245          244   \n",
       "4         15        15  ...           39           35           38   \n",
       "..       ...       ...  ...          ...          ...          ...   \n",
       "195       36        43  ...           16           16           17   \n",
       "196       14        15  ...           33           34           35   \n",
       "197       52        50  ...           89           86           85   \n",
       "198       54        47  ...          103           91          104   \n",
       "199      154       156  ...          122          102           82   \n",
       "\n",
       "     pixel_62495  pixel_62496  pixel_62497  pixel_62498  pixel_62499  \\\n",
       "0             29           30           29           27           25   \n",
       "1             35           36           36           36           37   \n",
       "2            164          163          162          161          160   \n",
       "3            242          244          246          249          251   \n",
       "4             46           53           62           70           79   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "195           18           19           18           17           17   \n",
       "196           35           36           36           36           36   \n",
       "197           84           81           69           58           47   \n",
       "198          135          166          171          169          167   \n",
       "199           62           43           37           37           36   \n",
       "\n",
       "     pixel_62500   label  \n",
       "0             25  female  \n",
       "1             37  female  \n",
       "2            160  female  \n",
       "3            251  female  \n",
       "4             80  female  \n",
       "..           ...     ...  \n",
       "195           17    male  \n",
       "196           36    male  \n",
       "197           47    male  \n",
       "198          167    male  \n",
       "199           36    male  \n",
       "\n",
       "[200 rows x 62501 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset, columns=[f'pixel_{i+1}' for i in range(250*250)] + ['label'])\n",
    "\n",
    "\"\"\"Print the DataFrame\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7ff8381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=df.drop('label',axis=1)\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f884887d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=X/255\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a849480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler , OneHotEncoder ,LabelEncoder ,MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d065309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>pixel_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_62491</th>\n",
       "      <th>pixel_62492</th>\n",
       "      <th>pixel_62493</th>\n",
       "      <th>pixel_62494</th>\n",
       "      <th>pixel_62495</th>\n",
       "      <th>pixel_62496</th>\n",
       "      <th>pixel_62497</th>\n",
       "      <th>pixel_62498</th>\n",
       "      <th>pixel_62499</th>\n",
       "      <th>pixel_62500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.145098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972549</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.984314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 62500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_1   pixel_2   pixel_3   pixel_4   pixel_5   pixel_6   pixel_7  \\\n",
       "0    0.223529  0.227451  0.270588  0.317647  0.352941  0.352941  0.352941   \n",
       "1    0.560784  0.556863  0.545098  0.529412  0.517647  0.509804  0.501961   \n",
       "2    0.039216  0.039216  0.039216  0.043137  0.043137  0.039216  0.039216   \n",
       "3    0.196078  0.196078  0.192157  0.188235  0.184314  0.180392  0.176471   \n",
       "4    0.078431  0.078431  0.070588  0.066667  0.062745  0.058824  0.054902   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.078431  0.078431  0.074510  0.074510  0.074510  0.086275  0.101961   \n",
       "196  0.086275  0.086275  0.082353  0.078431  0.074510  0.066667  0.058824   \n",
       "197  0.200000  0.200000  0.207843  0.219608  0.227451  0.227451  0.215686   \n",
       "198  0.250980  0.247059  0.223529  0.200000  0.184314  0.211765  0.235294   \n",
       "199  0.501961  0.501961  0.521569  0.541176  0.560784  0.572549  0.588235   \n",
       "\n",
       "      pixel_8   pixel_9  pixel_10  ...  pixel_62491  pixel_62492  pixel_62493  \\\n",
       "0    0.356863  0.360784  0.364706  ...     0.129412     0.117647     0.105882   \n",
       "1    0.501961  0.498039  0.494118  ...     0.141176     0.137255     0.137255   \n",
       "2    0.035294  0.039216  0.039216  ...     0.662745     0.662745     0.658824   \n",
       "3    0.172549  0.172549  0.168627  ...     0.972549     0.964706     0.960784   \n",
       "4    0.054902  0.058824  0.058824  ...     0.164706     0.152941     0.137255   \n",
       "..        ...       ...       ...  ...          ...          ...          ...   \n",
       "195  0.117647  0.141176  0.168627  ...     0.062745     0.062745     0.062745   \n",
       "196  0.050980  0.054902  0.058824  ...     0.121569     0.129412     0.133333   \n",
       "197  0.211765  0.203922  0.196078  ...     0.372549     0.349020     0.337255   \n",
       "198  0.239216  0.211765  0.184314  ...     0.450980     0.403922     0.356863   \n",
       "199  0.596078  0.603922  0.611765  ...     0.552941     0.478431     0.400000   \n",
       "\n",
       "     pixel_62494  pixel_62495  pixel_62496  pixel_62497  pixel_62498  \\\n",
       "0       0.105882     0.113725     0.117647     0.113725     0.105882   \n",
       "1       0.137255     0.137255     0.141176     0.141176     0.141176   \n",
       "2       0.650980     0.643137     0.639216     0.635294     0.631373   \n",
       "3       0.956863     0.949020     0.956863     0.964706     0.976471   \n",
       "4       0.149020     0.180392     0.207843     0.243137     0.274510   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "195     0.066667     0.070588     0.074510     0.070588     0.066667   \n",
       "196     0.137255     0.137255     0.141176     0.141176     0.141176   \n",
       "197     0.333333     0.329412     0.317647     0.270588     0.227451   \n",
       "198     0.407843     0.529412     0.650980     0.670588     0.662745   \n",
       "199     0.321569     0.243137     0.168627     0.145098     0.145098   \n",
       "\n",
       "     pixel_62499  pixel_62500  \n",
       "0       0.098039     0.098039  \n",
       "1       0.145098     0.145098  \n",
       "2       0.627451     0.627451  \n",
       "3       0.984314     0.984314  \n",
       "4       0.309804     0.313725  \n",
       "..           ...          ...  \n",
       "195     0.066667     0.066667  \n",
       "196     0.141176     0.141176  \n",
       "197     0.184314     0.184314  \n",
       "198     0.654902     0.654902  \n",
       "199     0.141176     0.141176  \n",
       "\n",
       "[200 rows x 62500 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f53e5",
   "metadata": {},
   "source": [
    "# (1): Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a56aa588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Model Accuracy: 0.7777777777777778\n",
      "Execution Time: 0.6873 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.64      0.88      0.74         8\n",
      "        male       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.75      0.74      0.72        18\n",
      "weighted avg       0.76      0.72      0.72        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_ml = LogisticRegression()\n",
    "model_ml.fit(X_train, y_train)\n",
    "y_pred_ml = model_ml.predict(X_test)\n",
    "accuracy_ml = accuracy_score(y_test, y_pred_ml)\n",
    "print(\"Machine Learning Model Accuracy:\", accuracy_ml)\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "class_report_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82688b5",
   "metadata": {},
   "source": [
    "# (2): SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3f08cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02b4a747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222222222222222\n",
      "Execution Time: 0.6873 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.71      0.62      0.67         8\n",
      "        male       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.72      0.71      0.71        18\n",
      "weighted avg       0.72      0.72      0.72        18\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 3]\n",
      " [2 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Predict the labels for the test set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# execution time\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "610e39b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      female\n",
       "1      female\n",
       "2      female\n",
       "3      female\n",
       "4      female\n",
       "        ...  \n",
       "195      male\n",
       "196      male\n",
       "197      male\n",
       "198      male\n",
       "199      male\n",
       "Name: label, Length: 200, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df.iloc[:,-1]\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66d62cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit and transform the labels into numeric values\n",
    "Y_encoded = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2172a825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>pixel_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_62492</th>\n",
       "      <th>pixel_62493</th>\n",
       "      <th>pixel_62494</th>\n",
       "      <th>pixel_62495</th>\n",
       "      <th>pixel_62496</th>\n",
       "      <th>pixel_62497</th>\n",
       "      <th>pixel_62498</th>\n",
       "      <th>pixel_62499</th>\n",
       "      <th>pixel_62500</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 62501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_1   pixel_2   pixel_3   pixel_4   pixel_5   pixel_6   pixel_7  \\\n",
       "0    0.223529  0.227451  0.270588  0.317647  0.352941  0.352941  0.352941   \n",
       "1    0.560784  0.556863  0.545098  0.529412  0.517647  0.509804  0.501961   \n",
       "2    0.039216  0.039216  0.039216  0.043137  0.043137  0.039216  0.039216   \n",
       "3    0.196078  0.196078  0.192157  0.188235  0.184314  0.180392  0.176471   \n",
       "4    0.078431  0.078431  0.070588  0.066667  0.062745  0.058824  0.054902   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.078431  0.078431  0.074510  0.074510  0.074510  0.086275  0.101961   \n",
       "196  0.086275  0.086275  0.082353  0.078431  0.074510  0.066667  0.058824   \n",
       "197  0.200000  0.200000  0.207843  0.219608  0.227451  0.227451  0.215686   \n",
       "198  0.250980  0.247059  0.223529  0.200000  0.184314  0.211765  0.235294   \n",
       "199  0.501961  0.501961  0.521569  0.541176  0.560784  0.572549  0.588235   \n",
       "\n",
       "      pixel_8   pixel_9  pixel_10  ...  pixel_62492  pixel_62493  pixel_62494  \\\n",
       "0    0.356863  0.360784  0.364706  ...     0.117647     0.105882     0.105882   \n",
       "1    0.501961  0.498039  0.494118  ...     0.137255     0.137255     0.137255   \n",
       "2    0.035294  0.039216  0.039216  ...     0.662745     0.658824     0.650980   \n",
       "3    0.172549  0.172549  0.168627  ...     0.964706     0.960784     0.956863   \n",
       "4    0.054902  0.058824  0.058824  ...     0.152941     0.137255     0.149020   \n",
       "..        ...       ...       ...  ...          ...          ...          ...   \n",
       "195  0.117647  0.141176  0.168627  ...     0.062745     0.062745     0.066667   \n",
       "196  0.050980  0.054902  0.058824  ...     0.129412     0.133333     0.137255   \n",
       "197  0.211765  0.203922  0.196078  ...     0.349020     0.337255     0.333333   \n",
       "198  0.239216  0.211765  0.184314  ...     0.403922     0.356863     0.407843   \n",
       "199  0.596078  0.603922  0.611765  ...     0.478431     0.400000     0.321569   \n",
       "\n",
       "     pixel_62495  pixel_62496  pixel_62497  pixel_62498  pixel_62499  \\\n",
       "0       0.113725     0.117647     0.113725     0.105882     0.098039   \n",
       "1       0.137255     0.141176     0.141176     0.141176     0.145098   \n",
       "2       0.643137     0.639216     0.635294     0.631373     0.627451   \n",
       "3       0.949020     0.956863     0.964706     0.976471     0.984314   \n",
       "4       0.180392     0.207843     0.243137     0.274510     0.309804   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "195     0.070588     0.074510     0.070588     0.066667     0.066667   \n",
       "196     0.137255     0.141176     0.141176     0.141176     0.141176   \n",
       "197     0.329412     0.317647     0.270588     0.227451     0.184314   \n",
       "198     0.529412     0.650980     0.670588     0.662745     0.654902   \n",
       "199     0.243137     0.168627     0.145098     0.145098     0.141176   \n",
       "\n",
       "     pixel_62500  Target  \n",
       "0       0.098039       0  \n",
       "1       0.145098       0  \n",
       "2       0.627451       0  \n",
       "3       0.984314       0  \n",
       "4       0.313725       0  \n",
       "..           ...     ...  \n",
       "195     0.066667       1  \n",
       "196     0.141176       1  \n",
       "197     0.184314       1  \n",
       "198     0.654902       1  \n",
       "199     0.141176       1  \n",
       "\n",
       "[200 rows x 62501 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series = pd.Series(Y_encoded, name='Target')\n",
    "df = pd.concat([X, y_series], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf571bb0",
   "metadata": {},
   "source": [
    "# (3): Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f421704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bc2860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cea604ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbba14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2df1412c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n",
      "Execution Time: 4.4242 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.56      0.62      0.59         8\n",
      "        male       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.61      0.61      0.61        18\n",
      "weighted avg       0.62      0.61      0.61        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a99d18",
   "metadata": {},
   "source": [
    "# (4): KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57e1b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train a k-NN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors\n",
    "start_time = time.time()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1854bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c590554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report_knn = classification_report(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91b622db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Classifier:\n",
      "Accuracy: 0.72\n",
      "Execution Time: 0.6873 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.64      0.88      0.74         8\n",
      "        male       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.75      0.74      0.72        18\n",
      "weighted avg       0.76      0.72      0.72        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"k-NN Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_knn:.2f}\")\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118b949",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8aa1e4",
   "metadata": {},
   "source": [
    "# Report: Gender Detection through Human Facial Images Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e7336",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341bd14",
   "metadata": {},
   "source": [
    "Gender detection from human facial images is a challenging and socially\n",
    "relevant problem in the field of computer vision and machine learning.\n",
    "This report presents an analysis of gender detection using a dataset of \n",
    "human facial images. The goal is to develop and evaluate a machine \n",
    "learning model that can accurately predict the gender of individuals\n",
    "based on their facial features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c2f2c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf832e",
   "metadata": {},
   "source": [
    "We have human facial images dataset containing both male and females."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ae35f",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788628e",
   "metadata": {},
   "source": [
    "The dataset used for this analysis consists of a diverse collection\n",
    "of human facial images. Each image is labeled with the gender of the \n",
    "individual as either \"male\" or \"female.\" The dataset contains a range \n",
    "of variations in terms of lighting conditions, poses, facial expressions,\n",
    "and ethnicities to ensure its representativeness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155f264",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0202aa02",
   "metadata": {},
   "source": [
    "The dataset was split into two subsets: a training set and a testing set.\n",
    "The training set, comprising 70% of the data, was used to train and\n",
    "optimize the machine learning model. The remaining 30% of the data \n",
    "formed the testing set, used to evaluate the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815795a5",
   "metadata": {},
   "source": [
    "## Methodology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a431adc",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9ccd6",
   "metadata": {},
   "source": [
    "For each image, a set of facial features was extracted.\n",
    "These features include landmarks, texture descriptors, and\n",
    "color histograms. Feature extraction was performed using \n",
    "established techniques from the computer vision field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022edba9",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7594b",
   "metadata": {},
   "source": [
    "# 1:  Decision Tree\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Path to the directory containing male and female face images\n",
    "# List of folder paths\n",
    "folder_paths = [\n",
    "    r\"C:\\Users\\user\\Desktop\\gender\\test\\female\",\n",
    "    r\"C:\\Users\\user\\Desktop\\gender\\test\\male\"\n",
    "    ]\n",
    "\n",
    "# Load and preprocess images\n",
    "# Iterate over the folder paths\n",
    "for i in folder_paths:\n",
    "    folder_name = os.path.basename(i)\n",
    "    \n",
    "    # Iterate over the images in the subdirectory\n",
    "    for file_name in os.listdir(i):\n",
    "        image_path = os.path.join(i, file_name)\n",
    "        \n",
    "        if os.path.isfile(image_path):  # Only consider files\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # If the image was successfully loaded\n",
    "            if image is not None:\n",
    "                # Resize the grayscale image to 250X250 pixels\n",
    "                resized_image = cv2.resize(image, (250, 250))\n",
    "                \n",
    "                # Flatten the image and append each pixel as a separate feature along with the label to the dataset\n",
    "                flattened_image = resized_image.flatten().tolist()\n",
    "                dataset.append(flattened_image + [folder_name])\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "# 2: SVM\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "for i in folder_paths:\n",
    "    folder_name = os.path.basename(i)\n",
    "    \n",
    "    # Iterate over the images in the subdirectory\n",
    "    for file_name in os.listdir(i):\n",
    "        image_path = os.path.join(i, file_name)\n",
    "        \n",
    "        if os.path.isfile(image_path):  # Only consider files\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # If the image was successfully loaded\n",
    "            if image is not None:\n",
    "                # Resize the grayscale image to 250X250 pixels\n",
    "                resized_image = cv2.resize(image, (250, 250))\n",
    "                \n",
    "                # Flatten the image and append each pixel as a separate feature along with the label to the dataset\n",
    "                flattened_image = resized_image.flatten().tolist()\n",
    "                dataset.append(flattened_image + [folder_name])\n",
    "\n",
    "# Load dataset\n",
    "folder_paths = [\n",
    "    r\"C:\\Users\\user\\Desktop\\gender\\test\\female\",\n",
    "    r\"C:\\Users\\user\\Desktop\\gender\\test\\male\"\n",
    "    ]\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "class_report_svm = classification_report(y_test, y_pred)\n",
    "\n",
    "# Calculate accuracy and classification report.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Classifier:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_svm)\n",
    "\n",
    "\n",
    "# 3: KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train a k-NN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors\n",
    "start_time = time.time()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "\n",
    "class_report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "\n",
    "print(\"k-NN Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_knn:.2f}\")\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_knn)\n",
    "\n",
    "\n",
    "# 4: Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "logreg_clf = LogisticRegression(random_state=42)\n",
    "start_time = time.time()\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logreg = logreg_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "\n",
    "class_report_logreg = classification_report(y_test, y_pred_logreg)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_logreg:.2f}\")\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_logreg)\n",
    "\n",
    "\n",
    "# Report: Gender Detection through Human Facial Images Dataset\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Gender detection from human facial images is a challenging and socially\n",
    "relevant problem in the field of computer vision and machine learning.\n",
    "This report presents an analysis of gender detection using a dataset of \n",
    "human facial images. The goal is to develop and evaluate a machine \n",
    "learning model that can accurately predict the gender of individuals\n",
    "based on their facial features.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We have human facial images dataset containing both male 100 pictures and females 100 pictures.\n",
    "\n",
    "### Description\n",
    "\n",
    "The dataset used for this analysis consists of a diverse collection\n",
    "of human facial images. Each image is labeled with the gender of the \n",
    "individual as either \"male\" or \"female.\" The dataset contains a range \n",
    "of variations in terms of lighting conditions, poses, facial expressions,\n",
    "and ethnicities to ensure its representativeness.\n",
    "\n",
    "\n",
    "### Data Split\n",
    "\n",
    "The dataset was split into two subsets: a training set and a testing set.\n",
    "The training set, comprising 70% of the data, was used to train and\n",
    "optimize the machine learning model. The remaining 30% of the data \n",
    "formed the testing set, used to evaluate the model's performance.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "For each image, a set of facial features was extracted.\n",
    "These features include landmarks, texture descriptors, and\n",
    "color histograms. Feature extraction was performed using \n",
    "established techniques from the computer vision field.\n",
    "\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "Two machine learning models were selected for this analysis: Decision Tree Classifier, SVM, Logistic Regression model and a Support Vector Machine (SVM).\n",
    "1. **Decision Tree**: Decision Trees are interpretable models that partition feature space based on the most discriminative features to make classification decisions.\n",
    "\n",
    "2. **Support Vector Machine (SVM)**: SVMs are a classical machine learning algorithm that can be effective for image classification tasks when combined with appropriate feature representations.\n",
    "\n",
    "3. **Logistic Regression**: Logistic Regression model is a classical machine learning algorithm that can be effective for image classification tasks when combined with appropriate feature representations.\n",
    "\n",
    "4. **k-Nearest Neighbors (KNN)**: KNN is a non-parametric algorithm that classifies a data point based on the majority class of its k-nearest neighbors in the feature space.\n",
    "\n",
    "### Model Training\n",
    "\n",
    "The selected models were trained on the training subset using appropriate training techniques for each model type. Hyperparameters were fine-tuned using methods such as grid search and cross-validation to optimize model performance.\n",
    "\n",
    "## Results\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "The ensuing table encapsulates the performance metrics of the four models on the testing set:\n",
    "\n",
    "| Model             | Accuracy | Precision | Recall | Execution Time |\n",
    "|-------------------|----------|-----------|--------|----------|\n",
    "| Logistic Regression| 0.78%    | 0.86     | 0.60  | 0.6873    |\n",
    "| SVM               | 0.72%    | 0.73     | 0.80  | 0.6873   |\n",
    "| KNN               | 0.72%    | 0.86     | 0.60  | 0.6873    |\n",
    "| Decision Tree     | 0.61%    | 0.67     | 0.67  | 4.4242   |\n",
    "\n",
    "### Discussion\n",
    "\n",
    "The results highlight that the  Logistic Regression model achieved the highest accuracy and overall performance among the four models, suggesting its ability to discern intricate facial features effectively. While the SVM, KNN, and Decision Tree models also demonstrated reasonable performance, the CNN exhibited superior predictive capabilities.\n",
    "\n",
    "\n",
    "## Challenges and Future Work\n",
    "\n",
    "1. **Data Imbalance**: Potential imbalances in gender representation within the dataset might impact model performance. Future efforts could involve employing techniques such as oversampling or synthetic data generation to address this challenge.\n",
    "\n",
    "2. **Ethnicity Bias**: Despite dataset diversity, underlying biases might still exist. It is crucial to collect and include data from various ethnic backgrounds to ensure fairness in gender predictions.\n",
    "\n",
    "3. **Real-World Applications**: Deploying the trained model in real-world applications such as security systems, marketing strategies, and customer analysis can yield valuable insights and benefits.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Gender detection from human facial images is a multifaceted task with wide-ranging implications. While the  Logistic Regression model displayed superior performance, all four models – CNN, SVM, KNN, and Decision Tree – demonstrated potential for gender prediction. As technology advances and more comprehensive datasets become accessible, gender detection systems can evolve to be more equitable, accurate, and applicable across diverse domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729b9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
